import express from 'express';\nimport dotenv from 'dotenv';\nimport OpenAI from 'openai';\nimport cors from 'cors';\n\n// Cargar variables de entorno desde .env\ndotenv.config();\n\nconst app = express();\nconst port = process.env.PORT || 3001; // Puerto para el servidor backend\n\n// Configuración de CORS para permitir peticiones desde el frontend\napp.use(cors());\napp.use(express.json()); // Middleware para parsear JSON\n\n// Inicializar cliente de OpenAI\n// Asegúrate de que la variable de entorno OPENAI_API_KEY esté definida en tu archivo .env\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n});\n\n/**\n * Endpoint POST /chat\n * Recibe un mensaje del usuario y devuelve la respuesta del modelo de OpenAI.\n * @param {object} req - El objeto de solicitud Express.\n * @param {string} req.body.message - El mensaje enviado por el usuario.\n * @param {object} res - El objeto de respuesta Express.\n */\napp.post('/chat', async (req, res) => {\n  const userMessage = req.body.message;\n\n  if (!userMessage) {\n    return res.status(400).json({ error: 'El mensaje es requerido.' });\n  }\n\n  try {\n    // Llamada a la API de OpenAI (Chat Completions)\n    // Usamos un modelo adecuado para conversación, como gpt-3.5-turbo o gpt-4 si tienes acceso.\n    // Incluimos un mensaje de sistema para guiar el comportamiento del agente.\n    const completion = await openai.chat.completions.create({\n      model: \"gpt-3.5-turbo\", // Puedes cambiar a \"gpt-4\" o \"gpt-4-turbo-preview\" si lo prefieres y tienes acceso\n      messages: [\n        {\n          role: \"system\",\n          content: \"Eres un agente de IA experto en inteligencia artificial y los últimos avances tecnológicos. Responde de forma concisa y útil a las preguntas del usuario.\"\n        },\n        {\n          role: \"user\",\n          content: userMessage\n        }\n      ],\n      temperature: 0.7, // Controla la creatividad de la respuesta (0.1 - 1.0)\n      max_tokens: 150, // Límite de tokens para la respuesta\n    });\n\n    // Extraer la respuesta del modelo\n    const assistantMessage = completion.choices[0]?.message?.content;\n\n    if (!assistantMessage) {\n      console.error('No se recibió contenido en la respuesta de OpenAI:', completion);\n      return res.status(500).json({ error: 'Error al obtener la respuesta del agente.' });\n    }\n\n    res.json({ reply: assistantMessage.trim() });\n  } catch (error) {\n    console.error('Error al contactar la API de OpenAI:', error);\n    // Devuelve un mensaje de error más genérico al cliente por seguridad\n    res.status(500).json({ error: 'Ocurrió un error interno al procesar tu solicitud.' });\n  }\n});\n\n// Iniciar el servidor\napp.listen(port, () => {\n  console.log(`Servidor backend escuchando en http://localhost:${port}`);\n});